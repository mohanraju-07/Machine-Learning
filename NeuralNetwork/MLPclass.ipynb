{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3efd0a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 0.34818619335949397\n",
      "\n",
      "Predictions:\n",
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "\n",
      "Class Output:\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP :\n",
    "    def __init__(self,input_size ,hidden_size,output_size,lr=0.1):\n",
    "        self.lr = lr \n",
    "\n",
    "        self.w1 = np.random.rand(input_size,hidden_size)+0.1\n",
    "        self.b1 =np.zeros((1,hidden_size))\n",
    "\n",
    "        self.w2 =np.random.rand(hidden_size,output_size) +0.1\n",
    "        self.b2 = np.zeros((1,output_size))\n",
    "\n",
    "\n",
    "        # activations \n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    def sigmoid_derivative(self, a):\n",
    "        return a*(1-a)\n",
    "    def Relu(self,z):\n",
    "        return np.maximum(0,z)\n",
    "    def relu_derivative(self , z):\n",
    "        return (z>0).astype(float)\n",
    "        \n",
    "        # forward pass \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 =np.dot(x,self.w1) +self.b1 \n",
    "        self.a1 = self.Relu(self.z1)\n",
    "\n",
    "        self.z2 = np.dot(self.a1,self.w2) +self.b2\n",
    "        self.a2 = self.Relu(self.z2)\n",
    "\n",
    "        return self.a2  \n",
    "        # back propagation \n",
    "\n",
    "    def backward(self,x,y):\n",
    "        m = len(x)\n",
    "\n",
    "        error = self.a2 -y \n",
    "        dz2 = error * self.relu_derivative(self.a2)\n",
    "        dw2 = np.dot(self.a1.T,dz2)/m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "\n",
    "        dz1 = np.dot(dz2,self.w2.T) * self.relu_derivative(self.a1)\n",
    "        dw1 = np.dot(x.T,dz1)/m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "\n",
    "                    # Update weights\n",
    "        self.w2 -= self.lr * dw2\n",
    "        self.b2 -= self.lr * db2\n",
    "\n",
    "        self.w1 -= self.lr * dw1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "        return np.mean(error**2)\n",
    "    \n",
    "    def fit(self ,x,y,epochs=2000):\n",
    "        for epochs in range(epochs):\n",
    "            self.forward(x)\n",
    "            loss = self.backward(x,y)\n",
    "\n",
    "            if epochs % 5000 == 0:\n",
    "                print(f\"Epoch {epochs}, Loss = {loss}\")\n",
    "\n",
    "    def predict(self,x):\n",
    "        a2 = self.forward(x)\n",
    "        return a2\n",
    "\n",
    "# XOR dataset\n",
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Create model\n",
    "model = MLP(input_size=2, hidden_size=2, output_size=1, lr=0.1)\n",
    "\n",
    "# Train\n",
    "model.fit(X, y, epochs=2000)\n",
    "\n",
    "# Predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(model.forward(X))\n",
    "print(\"\\nClass Output:\")\n",
    "#print(model.predict([0,1]))\n",
    "print((model.predict([1,0]) > 0.5).astype(int))\n",
    "\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
